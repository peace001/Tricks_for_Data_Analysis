{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import pandas and the train test split method\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TfidfTransformer**:  Term frequency times inverse document frequency\n",
    "**CountVectorizer** are just methods for feature extractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import the support vector machine model\n",
    "from sklearn import svm\n",
    "#we import  a collection of datasets called samples_generator\n",
    "from sklearn.datasets import samples_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Couple of feature selection methods\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, the pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # generate some data to play with\n",
    "X, y = samples_generator.make_classification(n_informative=5, n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, we take a row dataframe, we filter the features to select the most informatives ones using the\n",
    "#The selectKbest, and then, we give those to the SUpport Vector Classifier to fit the data and then predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intermediate steps are transforms methods which mean they can transform the dataframe into something ready to use by the estimator (classifier or regressor). We can chain many of them together making sure we understand the different steps (it is performed in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We set up the transformer\n",
    "# ANOVA SVM-C\n",
    "anova_filter = SelectKBest(f_regression, k=5)\n",
    "#We instantiate the estimator\n",
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We set the pipeline by chaining up transformers and estimator in order\n",
    "anova_svm = Pipeline([('anova', anova_filter), ('svc', clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('anova', SelectKBest(k=10, score_func=<function f_regression at 0x7fa339ae2bf8>)), ('svc', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can set the parameters using the names issued\n",
    "# For instance, fit using a k of 10 in the SelectKBest\n",
    "# and a parameter 'C' of the svm\n",
    "#We can tune parameters of the pipeline  by using the name of the transformer or estimators with the parameter \n",
    "#to be tuned separated by an underscore\n",
    "anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the pipeline is to assemble several steps that can be\n",
    "cross-validated together while setting different parameters.\n",
    "For this, it enables setting parameters of the various steps using their\n",
    "names and the parameter name separated by a '__'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now make the prediction\n",
    "prediction = anova_svm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova_svm.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False, False,  True,  True, False,\n",
       "        True, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # getting the selected features chosen by anova_filter\n",
    "anova_svm.named_steps['anova'].get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    \n",
    "    ('vectorizer1' , CountVectorizer()),\n",
    "    ('tfidf' , TfidfTransformer()),           \n",
    "    ('clf' , OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))\n",
    "    \n",
    "                 ])\n",
    "#('vectorizer2' , CountVectorizer()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/disque1/Apply/AIMS_CMR Talk/raw_messages.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>I've got ten bucks, jay is being noncomittal</td>\n",
       "      <td>nonspam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>4893</td>\n",
       "      <td>Miserable. They don't tell u that the side eff...</td>\n",
       "      <td>nonspam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>4599</td>\n",
       "      <td>I'm stuck in da middle of da row on da right h...</td>\n",
       "      <td>nonspam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>4968</td>\n",
       "      <td>You can donate £2.50 to UNICEF's Asian Tsunami...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            message    label\n",
       "1409        1409       I've got ten bucks, jay is being noncomittal  nonspam\n",
       "4893        4893  Miserable. They don't tell u that the side eff...  nonspam\n",
       "4599        4599  I'm stuck in da middle of da row on da right h...  nonspam\n",
       "4968        4968  You can donate £2.50 to UNICEF's Asian Tsunami...     spam"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df.label.map({'nonspam':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['class']\n",
    "y1 = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer1', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...lti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(vectorizer1__ngram_range = (1,2) ,tfidf__use_idf=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \n",
    "    'vectorizer_ngram_range': [(1,1) , (1,2)] , \n",
    "    'tfidf__use_idf':[True , False]\n",
    "    \n",
    "             }\n",
    "#'vectorizer_analyzer': ['word', 'char'],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f83c8bafe407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_clf_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "gs_clf_svm = GridSearchCV(model , parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fd21ac46d20, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/rock/.local/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/rock/.local/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/rock/..../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fd21ac46d20, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/rock/.local/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/rock/.local/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/rock/..../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf_svm=gs_clf_svm.fit(X,y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 19, 14, 30, 16, 598275, tzinfo=tzutc()), 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'session': '005535B507044DCEA9D0B07E2BFD05AD', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'005535B507044DCEA9D0B07E2BFD05AD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf_svm=gs_clf_svm.fit(X,y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 19, 14, 30, 16, 598275, tzinfo=tzutc()), 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'session': '005535B507044DCEA9D0B07E2BFD05AD', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'005535B507044DCEA9D0B07E2BFD05AD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf_svm=gs_clf_svm.fit(X,y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 19, 14, 30, 16, 598275, tzinfo=tzutc()), 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'session': '005535B507044DCEA9D0B07E2BFD05AD', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gs_clf_svm=gs_clf_svm.fit(X,y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gs_clf_svm=gs_clf_svm.fit(X,y)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gs_clf_svm=gs_clf_svm.fit(X,y)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gs_clf_svm=gs_clf_svm.fit(X,y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gs_clf_svm=gs_clf_svm.fit(X,y)', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-59-fcd5b7526d0b>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fd1e0098860, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fd1e0269f60, file \"<ipython-input-59-fcd5b7526d0b>\", line 1>\n        result = <ExecutionResult object at 7fd1e0098860, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fd1e0269f60, file \"<ipython-input-59-fcd5b7526d0b>\", line 1>, result=<ExecutionResult object at 7fd1e0098860, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fd1e0269f60, file \"<ipython-input-59-fcd5b7526d0b>\", line 1>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_splitain_test split', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', 'import sklearn as sk', 'from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer', 'from sklearn.multiclass import OneVsRestClassifier\\nfrom sklearn.svm import LinearSVC', 'model = Pipeline([\\'vectorizer\\' , CountVectorizer...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.pipeline import Pipeline', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.grid_search import GridSearchCV', \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", \"get_ipython().run_line_magic('pinfo', 'TfidfTransformer')\", \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", 'sklearn.__.version__', 'sk.__.version__', 'import sklearn as sk', 'sk.__.version__', 'sklearn.__version__', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {22: '0.19.0', 33:       Unnamed: 0                                ...ssed you tm of last night as my phone...  nonspam, 42: 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, 47: dict_keys(['clf__estimator__intercept_scaling', ..._analyzer', 'steps', 'clf__estimator__max_iter']), 55: dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'X': 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, '_': dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000]), ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_splitain_test split', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', 'import sklearn as sk', 'from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer', 'from sklearn.multiclass import OneVsRestClassifier\\nfrom sklearn.svm import LinearSVC', 'model = Pipeline([\\'vectorizer\\' , CountVectorizer...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.pipeline import Pipeline', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.grid_search import GridSearchCV', \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", \"get_ipython().run_line_magic('pinfo', 'TfidfTransformer')\", \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", 'sklearn.__.version__', 'sk.__.version__', 'import sklearn as sk', 'sk.__.version__', 'sklearn.__version__', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {22: '0.19.0', 33:       Unnamed: 0                                ...ssed you tm of last night as my phone...  nonspam, 42: 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, 47: dict_keys(['clf__estimator__intercept_scaling', ..._analyzer', 'steps', 'clf__estimator__max_iter']), 55: dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'X': 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, '_': dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000]), ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/rock/Desktop/Essais/<ipython-input-59-fcd5b7526d0b> in <module>()\n----> 1 gs_clf_svm=gs_clf_svm.fit(X,y)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object\n        y = 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64\n        self.param_grid = {'tfidf__use_idf': [True, False], 'vectorizer_ngram_range': [(1, 1), (1, 2)]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Mar 19 15:30:17 2018\nPID: 16287                                   Python 3.5.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=0, parameters={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        parameters = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **kwargs={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        kwargs = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), attr='steps', **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        params = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    278                 # simple objects case\n    279                 if key not in valid_params:\n    280                     raise ValueError('Invalid parameter %s for estimator %s. '\n    281                                      'Check the list of available parameters '\n    282                                      'with `estimator.get_params().keys()`.' %\n--> 283                                      (key, self.__class__.__name__))\n        key = 'vectorizer_ngram_range'\n        self.__class__.__name__ = 'Pipeline'\n    284                 setattr(self, key, value)\n    285         return self\n    286 \n    287     def __repr__(self):\n\nValueError: Invalid parameter vectorizer_ngram_range for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py\", line 1664, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\", line 144, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/base.py\", line 283, in set_params\n    (key, self.__class__.__name__))\nValueError: Invalid parameter vectorizer_ngram_range for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Mar 19 15:30:17 2018\nPID: 16287                                   Python 3.5.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=0, parameters={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        parameters = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **kwargs={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        kwargs = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), attr='steps', **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        params = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    278                 # simple objects case\n    279                 if key not in valid_params:\n    280                     raise ValueError('Invalid parameter %s for estimator %s. '\n    281                                      'Check the list of available parameters '\n    282                                      'with `estimator.get_params().keys()`.' %\n--> 283                                      (key, self.__class__.__name__))\n        key = 'vectorizer_ngram_range'\n        self.__class__.__name__ = 'Pipeline'\n    284                 setattr(self, key, value)\n    285         return self\n    286 \n    287     def __repr__(self):\n\nValueError: Invalid parameter vectorizer_ngram_range for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Mar 19 15:30:17 2018\nPID: 16287                                   Python 3.5.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=0, parameters={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        parameters = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **kwargs={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        kwargs = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), attr='steps', **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        params = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    278                 # simple objects case\n    279                 if key not in valid_params:\n    280                     raise ValueError('Invalid parameter %s for estimator %s. '\n    281                                      'Check the list of available parameters '\n    282                                      'with `estimator.get_params().keys()`.' %\n--> 283                                      (key, self.__class__.__name__))\n        key = 'vectorizer_ngram_range'\n        self.__class__.__name__ = 'Pipeline'\n    284                 setattr(self, key, value)\n    285         return self\n    286 \n    287     def __repr__(self):\n\nValueError: Invalid parameter vectorizer_ngram_range for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-fcd5b7526d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_clf_svm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs_clf_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 for train, test in cv)\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fd21ac46d20, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/rock/.local/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/rock/.local/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/rock/..../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fd21ac46d20, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/rock/.local/lib/python3.5/site-packages/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/rock/.local/lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/rock/..../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf_svm=gs_clf_svm.fit(X,y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 19, 14, 30, 16, 598275, tzinfo=tzutc()), 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'session': '005535B507044DCEA9D0B07E2BFD05AD', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'005535B507044DCEA9D0B07E2BFD05AD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf_svm=gs_clf_svm.fit(X,y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 19, 14, 30, 16, 598275, tzinfo=tzutc()), 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'session': '005535B507044DCEA9D0B07E2BFD05AD', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'005535B507044DCEA9D0B07E2BFD05AD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'gs_clf_svm=gs_clf_svm.fit(X,y)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 19, 14, 30, 16, 598275, tzinfo=tzutc()), 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'session': '005535B507044DCEA9D0B07E2BFD05AD', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '30D908A9E8FA4E09BF5564862A593BE3', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='gs_clf_svm=gs_clf_svm.fit(X,y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'gs_clf_svm=gs_clf_svm.fit(X,y)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('gs_clf_svm=gs_clf_svm.fit(X,y)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('gs_clf_svm=gs_clf_svm.fit(X,y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='gs_clf_svm=gs_clf_svm.fit(X,y)', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-59-fcd5b7526d0b>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fd1e0098860, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fd1e0269f60, file \"<ipython-input-59-fcd5b7526d0b>\", line 1>\n        result = <ExecutionResult object at 7fd1e0098860, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/rock/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fd1e0269f60, file \"<ipython-input-59-fcd5b7526d0b>\", line 1>, result=<ExecutionResult object at 7fd1e0098860, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fd1e0269f60, file \"<ipython-input-59-fcd5b7526d0b>\", line 1>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_splitain_test split', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', 'import sklearn as sk', 'from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer', 'from sklearn.multiclass import OneVsRestClassifier\\nfrom sklearn.svm import LinearSVC', 'model = Pipeline([\\'vectorizer\\' , CountVectorizer...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.pipeline import Pipeline', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.grid_search import GridSearchCV', \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", \"get_ipython().run_line_magic('pinfo', 'TfidfTransformer')\", \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", 'sklearn.__.version__', 'sk.__.version__', 'import sklearn as sk', 'sk.__.version__', 'sklearn.__version__', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {22: '0.19.0', 33:       Unnamed: 0                                ...ssed you tm of last night as my phone...  nonspam, 42: 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, 47: dict_keys(['clf__estimator__intercept_scaling', ..._analyzer', 'steps', 'clf__estimator__max_iter']), 55: dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'X': 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, '_': dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000]), ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_splitain_test split', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', 'import sklearn as sk', 'from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer', 'from sklearn.multiclass import OneVsRestClassifier\\nfrom sklearn.svm import LinearSVC', 'model = Pipeline([\\'vectorizer\\' , CountVectorizer...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.pipeline import Pipeline', 'model = Pipeline([(\\'vectorizer\\' , CountVectorize...lassifier(LinearSVC(class_weight=\"balanced\")))]) ', 'from sklearn.grid_search import GridSearchCV', \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", \"get_ipython().run_line_magic('pinfo', 'TfidfTransformer')\", \"get_ipython().run_line_magic('pinfo', 'GridSearchCV')\", 'sklearn.__.version__', 'sk.__.version__', 'import sklearn as sk', 'sk.__.version__', 'sklearn.__version__', 'import pandas as pd\\nfrom sklearn.model_selection import train_test_split', ...], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {22: '0.19.0', 33:       Unnamed: 0                                ...ssed you tm of last night as my phone...  nonspam, 42: 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, 47: dict_keys(['clf__estimator__intercept_scaling', ..._analyzer', 'steps', 'clf__estimator__max_iter']), 55: dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000])}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, 'X': 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, '_': dict_values([1, 'strict', CountVectorizer(analyz...1,\n     verbose=0),\n          n_jobs=1))], 1000]), ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/rock/Desktop/Essais/<ipython-input-59-fcd5b7526d0b> in <module>()\n----> 1 gs_clf_svm=gs_clf_svm.fit(X,y)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=0)>\n        X = 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object\n        y = 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64\n        self.param_grid = {'tfidf__use_idf': [True, False], 'vectorizer_ngram_range': [(1, 1), (1, 2)]}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=0), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Mar 19 15:30:17 2018\nPID: 16287                                   Python 3.5.3: /usr/bin/python3\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 0, {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0       0\n1       0\n2       1\n3       0\n4       ...5571    0\nName: class, Length: 5572, dtype: int64, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=0, parameters={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        parameters = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **kwargs={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    139 \n    140         Returns\n    141         -------\n    142         self\n    143         \"\"\"\n--> 144         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        kwargs = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n    145         return self\n    146 \n    147     def _validate_steps(self):\n    148         names, estimators = zip(*self.steps)\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), attr='steps', **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=0.0001,\n     verbose=0),\n          n_jobs=1))])>\n        params = {'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/usr/local/lib/python3.5/dist-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vectorizer1'...l=0.0001,\n     verbose=0),\n          n_jobs=1))]), **params={'tfidf__use_idf': True, 'vectorizer_ngram_range': (1, 1)})\n    278                 # simple objects case\n    279                 if key not in valid_params:\n    280                     raise ValueError('Invalid parameter %s for estimator %s. '\n    281                                      'Check the list of available parameters '\n    282                                      'with `estimator.get_params().keys()`.' %\n--> 283                                      (key, self.__class__.__name__))\n        key = 'vectorizer_ngram_range'\n        self.__class__.__name__ = 'Pipeline'\n    284                 setattr(self, key, value)\n    285         return self\n    286 \n    287     def __repr__(self):\n\nValueError: Invalid parameter vectorizer_ngram_range for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "gs_clf_svm=gs_clf_svm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       nonspam\n",
       "1       nonspam\n",
       "2          spam\n",
       "3       nonspam\n",
       "4       nonspam\n",
       "5          spam\n",
       "6       nonspam\n",
       "7       nonspam\n",
       "8          spam\n",
       "9          spam\n",
       "10      nonspam\n",
       "11         spam\n",
       "12         spam\n",
       "13      nonspam\n",
       "14      nonspam\n",
       "15         spam\n",
       "16      nonspam\n",
       "17      nonspam\n",
       "18      nonspam\n",
       "19         spam\n",
       "20      nonspam\n",
       "21      nonspam\n",
       "22      nonspam\n",
       "23      nonspam\n",
       "24      nonspam\n",
       "25      nonspam\n",
       "26      nonspam\n",
       "27      nonspam\n",
       "28      nonspam\n",
       "29      nonspam\n",
       "         ...   \n",
       "5542    nonspam\n",
       "5543    nonspam\n",
       "5544    nonspam\n",
       "5545    nonspam\n",
       "5546    nonspam\n",
       "5547       spam\n",
       "5548    nonspam\n",
       "5549    nonspam\n",
       "5550    nonspam\n",
       "5551    nonspam\n",
       "5552    nonspam\n",
       "5553    nonspam\n",
       "5554    nonspam\n",
       "5555    nonspam\n",
       "5556    nonspam\n",
       "5557    nonspam\n",
       "5558    nonspam\n",
       "5559    nonspam\n",
       "5560    nonspam\n",
       "5561    nonspam\n",
       "5562    nonspam\n",
       "5563    nonspam\n",
       "5564    nonspam\n",
       "5565    nonspam\n",
       "5566       spam\n",
       "5567       spam\n",
       "5568    nonspam\n",
       "5569    nonspam\n",
       "5570    nonspam\n",
       "5571    nonspam\n",
       "Name: label, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([None, [('vectorizer1', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)), ('clf', OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))], CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None), TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1), 'word', False, 'strict', <class 'numpy.int64'>, 'utf-8', 'content', True, 1.0, None, 1, (1, 1), None, None, None, '(?u)\\\\b\\\\w\\\\w+\\\\b', None, None, 'l2', True, False, True, 1.0, 'balanced', True, True, 1, 'squared_hinge', 1000, 'ovr', 'l2', None, 0.0001, 0, LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0), 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfTransformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
